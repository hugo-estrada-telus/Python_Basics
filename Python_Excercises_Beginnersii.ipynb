{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Words: 850474\n",
      "\n",
      "Top 20 Words:\n",
      "THE \t 26554\n",
      "AND \t 25002\n",
      "I \t 20224\n",
      "TO \t 18230\n",
      "OF \t 16650\n",
      "A \t 13930\n",
      "YOU \t 12846\n",
      "MY \t 11669\n",
      "IN \t 10777\n",
      "THAT \t 10406\n",
      "IS \t 8669\n",
      "NOT \t 7892\n",
      "WITH \t 7376\n",
      "ME \t 7201\n",
      "IT \t 7185\n",
      "FOR \t 7131\n",
      "HIS \t 6533\n",
      "BE \t 6390\n",
      "THIS \t 6247\n",
      "YOUR \t 6243\n"
     ]
    }
   ],
   "source": [
    "###1. Counting unique words\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def count_words(path):\n",
    "    with open(path, encoding='utf-8') as file:\n",
    "        all_words = re.findall(r\"[0-9a-zA-Z-']+\", file.read())\n",
    "        all_words = [word.upper() for word in all_words]\n",
    "        print('\\nTotal Words:', len(all_words))\n",
    "        \n",
    "        word_counts = Counter()\n",
    "        for word in all_words:\n",
    "            word_counts[word] += 1\n",
    "        \n",
    "        print('\\nTop 20 Words:')\n",
    "        for word in word_counts.most_common(20):\n",
    "            print(word[0], '\\t', word[1])\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    count_words('shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Merging CSV Files\n",
    "\n",
    "import csv\n",
    "\n",
    "def merge_csv(csv_list, output_path):\n",
    "    # build list with all fieldnames\n",
    "    fieldnames = list()\n",
    "    for file in csv_list:\n",
    "        with open(file, 'r') as input_csv:\n",
    "            fn = csv.DictReader(input_csv).fieldnames\n",
    "            fieldnames.extend(x for x in fn if x not in fieldnames)\n",
    "    \n",
    "    with open(output_path, 'w', newline='') as output_csv:\n",
    "        writer = csv.DictWriter(output_csv, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for file in csv_list:\n",
    "            with open(file, 'r') as input_csv:\n",
    "                reader = csv.DictReader(input_csv)\n",
    "                for row in reader:\n",
    "                    writer.writerow(row)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    merge_csv(['class1.csv', 'class2.csv'], 'all_students.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c'}\n"
     ]
    }
   ],
   "source": [
    "#3. Save a Dictionary\n",
    "\n",
    "import pickle\n",
    "\n",
    "def save_dict(dict_to_save, file_path):\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(dict_to_save, file)\n",
    "    \n",
    "def load_dict(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_dict = {1: 'a', 2: 'b', 3: 'c'}\n",
    "    save_dict(test_dict, 'test_dict.pickle')\n",
    "    recovered = load_dict('test_dict.pickle')\n",
    "    print(recovered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 ZIP a file\n",
    "\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "\n",
    "def zip_all(search_dir, extension_list, output_path):\n",
    "    with ZipFile(output_path, 'w') as output_zip:\n",
    "        for root, dirs, files in os.walk(search_dir):\n",
    "            rel_path = os.path.relpath(root, search_dir)\n",
    "            for file in files:\n",
    "                name, ext = os.path.splitext(file)\n",
    "                if ext.lower() in extension_list:\n",
    "                    output_zip.write(os.path.join(root, file),\n",
    "                                     arcname=os.path.join(rel_path, file))\n",
    "                    \n",
    "if __name__ == '__main__':\n",
    "    zip_all('.\\\\my_stuff', ['.jpg','.txt'], 'my_stuff.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 1], [0, 1], [1, 1]]\n",
      "[[0, 0], [1]]\n"
     ]
    }
   ],
   "source": [
    "def index_all(search_list, item):\n",
    "    indices = list()\n",
    "    for i in range(len(search_list)):\n",
    "        if search_list[i] == item:\n",
    "            indices.append([i])\n",
    "        elif isinstance(search_list[i], list):\n",
    "            for index in index_all(search_list[i], item):\n",
    "                indices.append([i]+index)\n",
    "    return indices\n",
    "\n",
    "if __name__ == '__main__':    \n",
    "    example = [[[1, 2, 3], 2, [1, 3]], [1, 2, 3]]\n",
    "    print(index_all(example, 2))\n",
    "    print(index_all(example, [1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
